% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/chat4R_streaming.R
\name{chat4R_streaming}
\alias{chat4R_streaming}
\title{chat4R_streaming: Interact with GPT-4o (default) with streaming using OpenAI API}
\usage{
chat4R_streaming(
  content,
  Model = "gpt-4o-mini",
  temperature = 1,
  api_key = Sys.getenv("OPENAI_API_KEY")
)
}
\arguments{
\item{content}{A string containing the user's input message.}

\item{Model}{A string specifying the GPT model to use (default: "GPT-4o").}

\item{temperature}{A numeric value controlling the randomness of the model's output (default: 1).}

\item{api_key}{A string containing the user's OpenAI API key.
Defaults to the value of the environment variable "OPENAI_API_KEY".}
}
\value{
A data frame containing the response from the GPT model.
}
\description{
This function uses the OpenAI API to interact with the
   GPT-4o model (default) and generates responses based on user input with
   streaming data back to R
   In this function, currently, "gpt-4o-mini", "gpt-4o", and "gpt-4-turbo"
   can be selected as OpenAI's LLM model.
}
\details{
Chat4R Function with Streaming
}
\examples{
\dontrun{
Sys.setenv(OPENAI_API_KEY = "Your API key")
response <- chat4R_streaming(content = "What is the capital of France?")
response
}
}
\author{
Satoshi Kume
}
